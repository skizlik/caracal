{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "956d5c62-7758-4699-a71d-1e05f35ded44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-08 15:19:39.537555: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-08 15:19:39.565620: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-08 15:19:40.003799: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow is available. Proceeding with the example.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Check for TensorFlow and other dependencies\n",
    "import caracal\n",
    "\n",
    "if not caracal.TENSORFLOW_AVAILABLE:\n",
    "    print(\"TensorFlow is not installed. Please install it with: pip install tensorflow\")\n",
    "else:\n",
    "    print(\"TensorFlow is available. Proceeding with the example.\")\n",
    "\n",
    "from caracal.data import DataHandler\n",
    "from caracal.core import KerasModelWrapper\n",
    "from caracal.config import ModelConfig\n",
    "from caracal.runners import ExperimentRunner\n",
    "from caracal.loggers import BaseLogger\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4af23e70-ba79-4e29-81e5-9a1bd9cbc398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Loading and Preparation ---\n",
    "class MNISTDataHandler(DataHandler):\n",
    "    \"\"\"A custom DataHandler to load and preprocess the built-in MNIST dataset.\"\"\"\n",
    "\n",
    "    @property\n",
    "    def data_type(self) -> str:\n",
    "        return \"image\"\n",
    "\n",
    "    @property\n",
    "    def return_format(self) -> str:\n",
    "        return \"split_arrays\"\n",
    "        \n",
    "    def __init__(self):\n",
    "        # We don't need a data_path for this handler, but the parent class\n",
    "        # expects one. We'll pass a placeholder and then override the validation.\n",
    "        super().__init__(data_path=\"\")\n",
    "\n",
    "    def _validate_data_path(self):\n",
    "        # We intentionally override the parent's validation because we are\n",
    "        # loading a built-in dataset, not a file from disk.\n",
    "        pass\n",
    "\n",
    "    def load(self, validation_split: float = 0.2, **kwargs) -> dict:\n",
    "        \"\"\"Loads and preprocesses the MNIST dataset.\"\"\"\n",
    "        print(\"Loading MNIST data from TensorFlow...\")\n",
    "        (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "        # Reshape data for CNN input (batch, height, width, channels)\n",
    "        X_train = np.expand_dims(X_train, axis=-1)\n",
    "        X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "        # Normalize pixel values from [0, 255] to [0.0, 1.0]\n",
    "        X_train = X_train.astype(\"float32\") / 255.0\n",
    "        X_test = X_test.astype(\"float32\") / 255.0\n",
    "\n",
    "        # Split training data into training and validation sets\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train, y_train, test_size=validation_split, random_state=42\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'train_data': (X_train, y_train),\n",
    "            'val_data': (X_val, y_val),\n",
    "            'test_data': (X_test, y_test)\n",
    "        }\n",
    "\n",
    "# Instantiate our custom data handler\n",
    "mnist_handler = MNISTDataHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd07328d-14c0-48e3-8ed1-4f2fc51b9115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Definition ---\n",
    "def create_simple_cnn(config: ModelConfig) -> KerasModelWrapper:\n",
    "    \"\"\"Builds a simple CNN for MNIST classification.\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return KerasModelWrapper(model)\n",
    "\n",
    "# --- Model Configuration ---\n",
    "model_config = ModelConfig({\n",
    "    'epochs': 5,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 0.001\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dce2134b-2b03-40e7-ada9-fa4fde247446",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled GPU memory growth\n",
      "Loading and preparing data...\n",
      "Loading MNIST data from TensorFlow...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m       0/11490434\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 0s/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-08 15:19:55.227095: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-08 15:19:55.282551: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-08 15:19:55.284798: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Data loaded successfully\n",
      "\n",
      "Starting Variability Study\n",
      "  Runs: 3\n",
      "  Epochs per run: 5\n",
      "  Execution mode: in standard mode\n",
      "\n",
      " - Run 1: Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-11-08 15:19:56.425395: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-08 15:19:56.427438: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-08 15:19:56.428990: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-08 15:19:56.538098: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-08 15:19:56.539107: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-08 15:19:56.539953: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-08 15:19:56.540761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4990 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762615197.483524    1038 service.cc:145] XLA service 0x767330003f70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1762615197.483546    1038 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2025-11-08 15:19:57.499233: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-11-08 15:19:57.578401: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "I0000 00:00:1762615198.661980    1038 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9879 - loss: 0.0376\n",
      " - Run 1: Completed successfully\n",
      " - Run 2: Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9903 - loss: 0.0306\n",
      " - Run 2: Completed successfully\n",
      " - Run 3: Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9884 - loss: 0.0350\n",
      " - Run 3: Completed successfully\n",
      "--------------------------------------------------\n",
      "\n",
      "Study Summary:\n",
      "  Successful runs: 3/3\n",
      "  Val accuracy: 0.9871 ± 0.0010\n",
      "\n",
      "==================================================\n",
      "Experiment Complete: Summary of Final Results\n",
      "Variability Study Results\n",
      "==============================\n",
      "Successful runs: 3\n",
      "Final validation accuracy:\n",
      "  Mean: 0.9871\n",
      "  Std:  0.0010\n",
      "  Min:  0.9863\n",
      "  Max:  0.9886\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'VariabilityStudyResults' object has no attribute 'to_dataframe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(study_results\u001b[38;5;241m.\u001b[39msummarize())\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Get a DataFrame of the final metrics for a more detailed view\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m results_df \u001b[38;5;241m=\u001b[39m \u001b[43mstudy_results\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFinal Metrics DataFrame:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(results_df)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VariabilityStudyResults' object has no attribute 'to_dataframe'"
     ]
    }
   ],
   "source": [
    "# --- Run the Experiment ---\n",
    "# Run a variability study with 3 runs\n",
    "study_results = caracal.run_variability_study(\n",
    "    model_builder=create_simple_cnn,\n",
    "    data_handler=mnist_handler,\n",
    "    model_config=model_config,\n",
    "    num_runs=3,\n",
    "    logger=BaseLogger()\n",
    ")\n",
    "\n",
    "# Print a summary of the results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Experiment Complete: Summary of Final Results\")\n",
    "print(study_results.summarize())\n",
    "\n",
    "# Get a DataFrame of the final metrics for a more detailed view\n",
    "results_df = study_results.to_dataframe()\n",
    "print(\"\\nFinal Metrics DataFrame:\")\n",
    "print(results_df)\n",
    "\n",
    "# --- Analysis ---\n",
    "# 5.1. Plotting the training histories\n",
    "all_histories = study_results.all_runs_metrics\n",
    "from caracal.plotting import plot_variability_summary\n",
    "\n",
    "print(\"\\nPlotting Variability Summary...\")\n",
    "plot_variability_summary(\n",
    "    all_runs_metrics_list=all_histories,\n",
    "    final_metrics_series=study_results.final_val_accuracies,\n",
    "    metric='accuracy',\n",
    "    show_boxplot=True\n",
    ")\n",
    "\n",
    "# 5.2. Statistical Comparison of Runs\n",
    "print(\"\\nPerforming Statistical Comparison of Runs...\")\n",
    "statistical_comparison = study_results.compare_models_statistically(\n",
    "    metric_name='val_accuracy'\n",
    ")\n",
    "\n",
    "overall_result = statistical_comparison['overall_test']\n",
    "\n",
    "print(\"\\nOverall Statistical Test Result:\")\n",
    "print(f\"Test Name: {overall_result.test_name}\")\n",
    "print(f\"Statistic: {overall_result.statistic:.4f}\")\n",
    "print(f\"P-value: {overall_result.p_value:.4f}\")\n",
    "\n",
    "if overall_result.is_significant():\n",
    "    print(\"Conclusion: There is a statistically significant difference between the runs.\")\n",
    "else:\n",
    "    print(\"Conclusion: There is no statistically significant difference between the runs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bf4a84-b522-4f39-891f-e1dd298b75fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
