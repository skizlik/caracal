{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "956d5c62-7758-4699-a71d-1e05f35ded44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 22:11:11.439792: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-17 22:11:11.468957: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-17 22:11:11.918549: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow is available. Proceeding with the example.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Check for TensorFlow and other dependencies\n",
    "import caracal\n",
    "\n",
    "if not caracal.TENSORFLOW_AVAILABLE:\n",
    "    print(\"TensorFlow is not installed. Please install it with: pip install tensorflow\")\n",
    "else:\n",
    "    print(\"TensorFlow is available. Proceeding with the example.\")\n",
    "\n",
    "from caracal.data import DataHandler\n",
    "from caracal.core import KerasModelWrapper\n",
    "from caracal.config import ModelConfig\n",
    "from caracal.runners import ExperimentRunner\n",
    "from caracal.loggers import BaseLogger\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4af23e70-ba79-4e29-81e5-9a1bd9cbc398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Loading and Preparation ---\n",
    "class MNISTDataHandler(DataHandler):\n",
    "    \"\"\"A custom DataHandler to load and preprocess the built-in MNIST dataset.\"\"\"\n",
    "\n",
    "    @property\n",
    "    def data_type(self) -> str:\n",
    "        return \"image\"\n",
    "\n",
    "    @property\n",
    "    def return_format(self) -> str:\n",
    "        return \"split_arrays\"\n",
    "        \n",
    "    def __init__(self):\n",
    "        # We don't need a data_path for this handler, but the parent class\n",
    "        # expects one. We'll pass a placeholder and then override the validation.\n",
    "        super().__init__(data_path=\"\")\n",
    "\n",
    "    def _validate_data_path(self):\n",
    "        # We intentionally override the parent's validation because we are\n",
    "        # loading a built-in dataset, not a file from disk.\n",
    "        pass\n",
    "\n",
    "    def load(self, validation_split: float = 0.2, **kwargs) -> dict:\n",
    "        \"\"\"Loads and preprocesses the MNIST dataset.\"\"\"\n",
    "        print(\"Loading MNIST data from TensorFlow...\")\n",
    "        (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "        # Reshape data for CNN input (batch, height, width, channels)\n",
    "        X_train = np.expand_dims(X_train, axis=-1)\n",
    "        X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "        # Normalize pixel values from [0, 255] to [0.0, 1.0]\n",
    "        X_train = X_train.astype(\"float32\") / 255.0\n",
    "        X_test = X_test.astype(\"float32\") / 255.0\n",
    "\n",
    "        # Split training data into training and validation sets\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train, y_train, test_size=validation_split, random_state=42\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'train_data': (X_train, y_train),\n",
    "            'val_data': (X_val, y_val),\n",
    "            'test_data': (X_test, y_test)\n",
    "        }\n",
    "\n",
    "# Instantiate our custom data handler\n",
    "mnist_handler = MNISTDataHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd07328d-14c0-48e3-8ed1-4f2fc51b9115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Definition ---\n",
    "def create_simple_cnn(config: ModelConfig) -> KerasModelWrapper:\n",
    "    \"\"\"Builds a simple CNN for MNIST classification.\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return KerasModelWrapper(model)\n",
    "\n",
    "# --- Model Configuration ---\n",
    "model_config = ModelConfig({\n",
    "    'epochs': 5,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 0.001\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce2134b-2b03-40e7-ada9-fa4fde247446",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled GPU memory growth\n",
      "Loading and preparing data...\n",
      "Loading MNIST data from TensorFlow...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 22:11:20.537368: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-17 22:11:20.598141: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-17 22:11:20.605057: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1us/step\n",
      "Data loaded successfully\n",
      "\n",
      "Starting Variability Study\n",
      "  Runs: 16\n",
      "  Epochs per run: 5\n",
      "  Execution mode: in standard mode\n",
      "\n",
      " - Run 1: Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-11-17 22:11:37.953887: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-17 22:11:37.955788: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-17 22:11:37.957540: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-17 22:11:38.062502: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-17 22:11:38.063429: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-17 22:11:38.064264: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-17 22:11:38.065053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4534 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1763417498.949050   36324 service.cc:145] XLA service 0x78d51401c5b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1763417498.949079   36324 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2025-11-17 22:11:38.962747: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-11-17 22:11:39.035188: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "I0000 00:00:1763417499.986062   36324 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9902 - loss: 0.0330\n",
      " - Run 1: Completed successfully\n",
      " - Run 2: Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9896 - loss: 0.0311\n",
      " - Run 2: Completed successfully\n",
      " - Run 3: Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9879 - loss: 0.0362\n",
      " - Run 3: Completed successfully\n",
      " - Run 4: Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9857 - loss: 0.0416\n",
      " - Run 4: Completed successfully\n",
      " - Run 5: Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9907 - loss: 0.0307\n",
      " - Run 5: Completed successfully\n",
      " - Run 6: Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9897 - loss: 0.0299\n",
      " - Run 6: Completed successfully\n",
      " - Run 7: Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9910 - loss: 0.0291\n",
      " - Run 7: Completed successfully\n",
      " - Run 8: Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9895 - loss: 0.0344\n",
      " - Run 8: Completed successfully\n",
      " - Run 9: Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9895 - loss: 0.0340\n",
      " - Run 9: Completed successfully\n",
      " - Run 10: Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9887 - loss: 0.0374\n",
      " - Run 10: Completed successfully\n",
      "  Memory check: 2737.1MB\n",
      " - Run 11: Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# --- Run the Experiment ---\n",
    "# Run a variability study with 16 runs\n",
    "study_results = caracal.run_variability_study(\n",
    "    model_builder=create_simple_cnn,\n",
    "    data_handler=mnist_handler,\n",
    "    model_config=model_config,\n",
    "    num_runs=16,\n",
    "    logger=BaseLogger()\n",
    ")\n",
    "\n",
    "# Print a summary of the results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Experiment Complete: Summary of Final Results\")\n",
    "print(study_results.summarize())\n",
    "\n",
    "# Get a DataFrame of the final metrics for a more detailed view\n",
    "results_df = study_results.to_dataframe()\n",
    "print(\"\\nFinal Metrics DataFrame:\")\n",
    "print(results_df)\n",
    "\n",
    "# --- Analysis ---\n",
    "# 5.1. Plotting the training histories\n",
    "all_histories = study_results.all_runs_metrics\n",
    "from caracal.plotting import plot_variability_summary\n",
    "\n",
    "print(\"\\nPlotting Variability Summary...\")\n",
    "plot_variability_summary(\n",
    "    all_runs_metrics_list=all_histories,\n",
    "    final_metrics_series=study_results.final_val_accuracies,\n",
    "    metric='accuracy',\n",
    "    show_boxplot=True\n",
    ")\n",
    "\n",
    "# 5.2. Statistical Comparison of Runs\n",
    "print(\"\\nPerforming Statistical Comparison of Runs...\")\n",
    "statistical_comparison = study_results.compare_models_statistically(\n",
    "    metric_name='val_accuracy'\n",
    ")\n",
    "\n",
    "overall_result = statistical_comparison['overall_test']\n",
    "\n",
    "print(\"\\nOverall Statistical Test Result:\")\n",
    "print(f\"Test Name: {overall_result.test_name}\")\n",
    "print(f\"Statistic: {overall_result.statistic:.4f}\")\n",
    "print(f\"P-value: {overall_result.p_value:.4f}\")\n",
    "\n",
    "if overall_result.is_significant():\n",
    "    print(\"Conclusion: There is a statistically significant difference between the runs.\")\n",
    "else:\n",
    "    print(\"Conclusion: There is no statistically significant difference between the runs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bf4a84-b522-4f39-891f-e1dd298b75fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
