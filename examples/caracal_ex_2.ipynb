{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06c8697f-912f-4baf-a0df-cc324a36aea9",
   "metadata": {},
   "source": [
    "## Caracal example notebook 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda5178b-bd0b-4d18-bd7c-0d3a1f761fe0",
   "metadata": {},
   "source": [
    "This notebook demonstrates the sklearn plotting function.  It's still being tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6881dcf8-0edd-43eb-b565-58fce8438502",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 21:12:07.952325: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-01 21:12:07.981451: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-01 21:12:08.422240: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import caracal as cr\n",
    "from caracal import ModelConfig, ScikitLearnModelWrapper, TabularDataHandler\n",
    "# the new sklearn-specific plotting function\n",
    "from caracal.plotting import plot_sklearn_variability_summary\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tempfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8263055b-2db2-49f7-a58a-75eb2c155a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Loading Iris Dataset...\n",
      "   Dataset shape: (150, 5)\n",
      "   Classes: ['setosa', 'versicolor', 'virginica']\n",
      "   Class distribution:\n",
      "     setosa: 50 samples\n",
      "     versicolor: 50 samples\n",
      "     virginica: 50 samples\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare iris dataset\n",
    "print(\"\\n1. Loading Iris Dataset...\")\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['target'] = iris.target\n",
    "\n",
    "print(f\"   Dataset shape: {iris_df.shape}\")\n",
    "print(f\"   Classes: {list(iris.target_names)}\")\n",
    "print(f\"   Class distribution:\")\n",
    "for i, name in enumerate(iris.target_names):\n",
    "    count = sum(iris.target == i)\n",
    "    print(f\"     {name}: {count} samples\")\n",
    "\n",
    "# Save to temporary CSV for TabularDataHandler\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "iris_path = os.path.join(temp_dir, 'iris.csv')\n",
    "iris_df.to_csv(iris_path, index=False)\n",
    "\n",
    "# Create data handler\n",
    "data_handler = TabularDataHandler(\n",
    "    data_path=iris_path,\n",
    "    target_column='target'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b54965a-aea0-4a4d-97ed-282b619a366c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Running Random Forest Variability Study...\n",
      "Loading and preparing data...\n",
      "Loaded tabular data: 150 rows, 5 columns\n",
      "Target column: target\n",
      "Feature columns: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Starting Variability Study for 8 runs in standard mode.\n",
      " - Training model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 21:12:13.691763: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-01 21:12:13.748494: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-01 21:12:13.750867: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Run 1 completed.\n",
      " - Training model 2...\n",
      " - Run 2 completed.\n",
      " - Training model 3...\n",
      " - Run 3 completed.\n",
      " - Training model 4...\n",
      " - Run 4 completed.\n",
      " - Training model 5...\n",
      " - Run 5 completed.\n",
      " - Training model 6...\n",
      " - Run 6 completed.\n",
      " - Training model 7...\n",
      " - Run 7 completed.\n",
      " - Training model 8...\n",
      " - Run 8 completed.\n",
      "--------------------------------------------------\n",
      "\n",
      "Random Forest Results:\n",
      "Variability Study Results\n",
      "==============================\n",
      "Number of runs: 8\n",
      "Available metrics: accuracy, epoch, run_num, train_accuracy, train_loss, val_accuracy, val_loss\n",
      "\n",
      "Final Validation Accuracy:\n",
      "  Mean: 0.8917\n",
      "  Std:  0.0323\n",
      "  Min:  0.8667\n",
      "  Max:  0.9333\n",
      "\n",
      "Final Test Accuracy:\n",
      "  Mean: 1.0000\n",
      "  Std:  0.0000\n",
      "  Min:  1.0000\n",
      "  Max:  1.0000\n",
      "\n",
      "Detailed Analysis:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to Series.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m rf_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(rf_accuracies\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDetailed Analysis:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest accuracies: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mv\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mrf_values]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Mean: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(rf_values)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mstd(rf_values)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Range: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmin(rf_values)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmax(rf_values)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 48\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     45\u001b[0m rf_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(rf_accuracies\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDetailed Analysis:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest accuracies: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mv\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mrf_values]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Mean: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(rf_values)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mstd(rf_values)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Range: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmin(rf_values)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmax(rf_values)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to Series.__format__"
     ]
    }
   ],
   "source": [
    "# Model builder with variability (different random seeds)\n",
    "def create_random_forest_with_variability(config):\n",
    "    \"\"\"Create Random Forest with different random seed each run.\"\"\"\n",
    "    global _run_counter\n",
    "    _run_counter += 1\n",
    "    \n",
    "    base_seed = config.get('base_seed', 42)\n",
    "    current_seed = base_seed + _run_counter\n",
    "    \n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=config.get('n_estimators', 100),\n",
    "        max_depth=config.get('max_depth', None),\n",
    "        min_samples_split=config.get('min_samples_split', 2),\n",
    "        min_samples_leaf=config.get('min_samples_leaf', 1),\n",
    "        random_state=current_seed,\n",
    "        bootstrap=True\n",
    "    )\n",
    "    \n",
    "    return ScikitLearnModelWrapper(rf, model_id=f\"random_forest_run_{_run_counter}\")\n",
    "\n",
    "# Test configuration\n",
    "rf_config = ModelConfig({\n",
    "    'n_estimators': 50,\n",
    "    'max_depth': 4,\n",
    "    'min_samples_split': 5,\n",
    "    'base_seed': 42\n",
    "})\n",
    "\n",
    "print(f\"\\n2. Running Random Forest Variability Study...\")\n",
    "_run_counter = 0  # Reset counter\n",
    "\n",
    "rf_results = cr.run_variability_study(\n",
    "    model_builder=create_random_forest_with_variability,\n",
    "    data_handler=data_handler,\n",
    "    model_config=rf_config,\n",
    "    num_runs=8,  # Reasonable number for testing\n",
    "    epochs_per_run=None\n",
    ")\n",
    "\n",
    "print(f\"\\nRandom Forest Results:\")\n",
    "print(rf_results.summarize())\n",
    "\n",
    "# Extract and analyze results\n",
    "rf_accuracies = rf_results.get_final_metrics('val_accuracy')\n",
    "rf_values = list(rf_accuracies.values())\n",
    "\n",
    "print(f\"\\nDetailed Analysis:\")\n",
    "print(f\"Random Forest accuracies: {[f'{v:.3f}' for v in rf_values]}\")\n",
    "print(f\"  Mean: {np.mean(rf_values):.4f} ± {np.std(rf_values):.4f}\")\n",
    "print(f\"  Range: [{np.min(rf_values):.3f}, {np.max(rf_values):.3f}]\")\n",
    "print(f\"  Coefficient of Variation: {np.std(rf_values)/np.mean(rf_values)*100:.1f}%\")\n",
    "\n",
    "# Test the new sklearn-specific plotting functionality\n",
    "print(f\"\\n3. Testing sklearn-Specific Plotting Functions...\")\n",
    "\n",
    "try:\n",
    "    print(\"   Creating sklearn variability summary plot...\")\n",
    "    plot_sklearn_variability_summary(\n",
    "        all_runs_metrics_list=rf_results.all_runs_metrics,\n",
    "        final_metrics_series=rf_results.final_val_accuracies,\n",
    "        metric='accuracy',\n",
    "        show_individual_runs=True,\n",
    "        show_histogram=True, \n",
    "        show_boxplot=True\n",
    "    )\n",
    "    \n",
    "    print(\"   sklearn plotting completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   sklearn plotting failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# Test statistical analysis if available\n",
    "print(f\"\\n4. Testing Statistical Analysis...\")\n",
    "\n",
    "try:\n",
    "    from caracal.analysis import mann_whitney_test, shapiro_wilk_test\n",
    "    \n",
    "    # Test normality of results\n",
    "    rf_series = pd.Series(rf_values, name='Random Forest Accuracy')\n",
    "    \n",
    "    normality_result = shapiro_wilk_test(rf_series)\n",
    "    print(f\"   Normality Test (Shapiro-Wilk):\")\n",
    "    print(f\"     W statistic: {normality_result.statistic:.4f}\")\n",
    "    print(f\"     P-value: {normality_result.p_value:.4f}\")\n",
    "    print(f\"     Normal distribution: {'Yes' if not normality_result.is_significant() else 'No'}\")\n",
    "    \n",
    "    # Test if results are significantly different from 90% accuracy\n",
    "    high_performance = pd.Series([0.9] * len(rf_values), name='90% Benchmark')\n",
    "    \n",
    "    benchmark_test = mann_whitney_test(rf_series, high_performance)\n",
    "    print(f\"\\n   Benchmark Comparison (vs 90% accuracy):\")\n",
    "    print(f\"     Mann-Whitney U: {benchmark_test.statistic:.3f}\")\n",
    "    print(f\"     P-value: {benchmark_test.p_value:.4f}\")\n",
    "    print(f\"     Effect size: {benchmark_test.effect_size:.3f} ({benchmark_test.effect_size_interpretation})\")\n",
    "    print(f\"     Conclusion: {benchmark_test.conclusion}\")\n",
    "    \n",
    "    print(f\"   Statistical analysis completed successfully!\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(f\"   Statistical analysis not available (missing scipy)\")\n",
    "except Exception as e:\n",
    "    print(f\"   Statistical analysis failed: {e}\")\n",
    "\n",
    "# Test enhanced results object methods\n",
    "print(f\"\\n5. Testing Enhanced Results Object...\")\n",
    "\n",
    "try:\n",
    "    available_metrics = rf_results.get_available_metrics()\n",
    "    print(f\"   Available metrics: {available_metrics}\")\n",
    "    \n",
    "    # Test DataFrame conversion\n",
    "    results_df = rf_results.to_dataframe()\n",
    "    print(f\"   Results DataFrame: {results_df.shape}\")\n",
    "    print(f\"   Sample of results:\")\n",
    "    print(results_df[['run_id', 'final_val_accuracy']].head(3).to_string(index=False))\n",
    "    \n",
    "    print(f\"   Enhanced results object working correctly!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   Enhanced results object failed: {e}\")\n",
    "\n",
    "# Cleanup\n",
    "print(f\"\\n6. Cleanup...\")\n",
    "try:\n",
    "    os.unlink(iris_path)\n",
    "    os.rmdir(temp_dir)\n",
    "    print(f\"   Temporary files cleaned up successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"   Cleanup warning: {e}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"SKLEARN TEST COMPLETED!\")\n",
    "print(f\"Random Forest Performance: {np.mean(rf_values):.4f} ± {np.std(rf_values):.4f}\")\n",
    "print(f\"Framework Status: ✓ sklearn models working with appropriate visualization\")\n",
    "print(f\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500dd10c-a058-4df6-ba5e-47cc99aabeeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
