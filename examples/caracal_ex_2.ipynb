{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06c8697f-912f-4baf-a0df-cc324a36aea9",
   "metadata": {},
   "source": [
    "## Caracal example notebook 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda5178b-bd0b-4d18-bd7c-0d3a1f761fe0",
   "metadata": {},
   "source": [
    "This notebook demonstrates the sklearn plotting function.  It's still being tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6881dcf8-0edd-43eb-b565-58fce8438502",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-16 20:42:06.127299: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-16 20:42:06.156572: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-16 20:42:06.606110: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import caracal as cr\n",
    "from caracal import ModelConfig, ScikitLearnModelWrapper, TabularDataHandler\n",
    "# the new sklearn-specific plotting function\n",
    "from caracal.plotting import plot_sklearn_variability_summary\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tempfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8263055b-2db2-49f7-a58a-75eb2c155a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Loading Iris Dataset...\n",
      "   Dataset shape: (150, 5)\n",
      "   Classes: ['setosa', 'versicolor', 'virginica']\n",
      "   Class distribution:\n",
      "     setosa: 50 samples\n",
      "     versicolor: 50 samples\n",
      "     virginica: 50 samples\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare iris dataset\n",
    "print(\"\\n1. Loading Iris Dataset...\")\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['target'] = iris.target\n",
    "\n",
    "print(f\"   Dataset shape: {iris_df.shape}\")\n",
    "print(f\"   Classes: {list(iris.target_names)}\")\n",
    "print(f\"   Class distribution:\")\n",
    "for i, name in enumerate(iris.target_names):\n",
    "    count = sum(iris.target == i)\n",
    "    print(f\"     {name}: {count} samples\")\n",
    "\n",
    "# Save to temporary CSV for TabularDataHandler\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "iris_path = os.path.join(temp_dir, 'iris.csv')\n",
    "iris_df.to_csv(iris_path, index=False)\n",
    "\n",
    "# Create data handler\n",
    "data_handler = TabularDataHandler(\n",
    "    data_path=iris_path,\n",
    "    target_column='target'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b54965a-aea0-4a4d-97ed-282b619a366c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-16 20:42:07.826799: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-16 20:42:07.870545: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-16 20:42:07.872190: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Running Random Forest Variability Study...\n",
      "Loading and preparing data...\n",
      "Loaded tabular data: 150 rows, 5 columns\n",
      "Target column: target\n",
      "Feature columns: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Starting Variability Study for 8 runs.\n",
      "Parameters: {'n_estimators': 50, 'max_depth': 4, 'min_samples_split': 5, 'base_seed': 42}\n",
      "Parameters: {'n_estimators': 50, 'max_depth': 4, 'min_samples_split': 5, 'base_seed': 42, 'num_runs': 8, 'epochs_per_run': 10}\n",
      "Parameters: {'n_estimators': 50, 'max_depth': 4, 'min_samples_split': 5, 'base_seed': 42, 'num_runs': 8, 'epochs_per_run': 10, 'run_num': 1}\n",
      " - Training model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-16 20:42:07.934599: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-16 20:42:07.936238: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-16 20:42:07.937398: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-16 20:42:08.036315: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-16 20:42:08.037942: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-16 20:42:08.039008: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-16 20:42:08.040038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1126 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU reset warning for /physical_device:GPU:0: Failed parsing device name: '/physical_device:GPU:0'. Note a valid device string should at least contain a device type and a device index, like \"GPU:0\".\n",
      " - Step 1: final_val_accuracy = 0.9333\n",
      " - Step 1: final_test_accuracy = 1.0000\n",
      " - Run 1 completed.\n",
      "GPU reset warning for /physical_device:GPU:0: Failed parsing device name: '/physical_device:GPU:0'. Note a valid device string should at least contain a device type and a device index, like \"GPU:0\".\n",
      "Parameters: {'n_estimators': 50, 'max_depth': 4, 'min_samples_split': 5, 'base_seed': 42, 'num_runs': 8, 'epochs_per_run': 10, 'run_num': 2}\n",
      " - Training model 2...\n",
      "GPU reset warning for /physical_device:GPU:0: Failed parsing device name: '/physical_device:GPU:0'. Note a valid device string should at least contain a device type and a device index, like \"GPU:0\".\n",
      " - Step 2: final_val_accuracy = 0.8667\n",
      " - Step 2: final_test_accuracy = 1.0000\n",
      " - Run 2 completed.\n",
      "GPU reset warning for /physical_device:GPU:0: Failed parsing device name: '/physical_device:GPU:0'. Note a valid device string should at least contain a device type and a device index, like \"GPU:0\".\n",
      "Parameters: {'n_estimators': 50, 'max_depth': 4, 'min_samples_split': 5, 'base_seed': 42, 'num_runs': 8, 'epochs_per_run': 10, 'run_num': 3}\n",
      " - Training model 3...\n",
      "GPU reset warning for /physical_device:GPU:0: Failed parsing device name: '/physical_device:GPU:0'. Note a valid device string should at least contain a device type and a device index, like \"GPU:0\".\n",
      " - Step 3: final_val_accuracy = 0.8667\n",
      " - Step 3: final_test_accuracy = 1.0000\n",
      " - Run 3 completed.\n",
      "GPU reset warning for /physical_device:GPU:0: Failed parsing device name: '/physical_device:GPU:0'. Note a valid device string should at least contain a device type and a device index, like \"GPU:0\".\n",
      "Parameters: {'n_estimators': 50, 'max_depth': 4, 'min_samples_split': 5, 'base_seed': 42, 'num_runs': 8, 'epochs_per_run': 10, 'run_num': 4}\n",
      " - Training model 4...\n",
      "GPU reset warning for /physical_device:GPU:0: Failed parsing device name: '/physical_device:GPU:0'. Note a valid device string should at least contain a device type and a device index, like \"GPU:0\".\n",
      " - Step 4: final_val_accuracy = 0.8667\n",
      " - Step 4: final_test_accuracy = 1.0000\n",
      " - Run 4 completed.\n",
      "GPU reset warning for /physical_device:GPU:0: Failed parsing device name: '/physical_device:GPU:0'. Note a valid device string should at least contain a device type and a device index, like \"GPU:0\".\n",
      "Parameters: {'n_estimators': 50, 'max_depth': 4, 'min_samples_split': 5, 'base_seed': 42, 'num_runs': 8, 'epochs_per_run': 10, 'run_num': 5}\n",
      " - Training model 5...\n",
      "GPU reset warning for /physical_device:GPU:0: Failed parsing device name: '/physical_device:GPU:0'. Note a valid device string should at least contain a device type and a device index, like \"GPU:0\".\n",
      " - Step 5: final_val_accuracy = 0.8667\n",
      " - Step 5: final_test_accuracy = 1.0000\n",
      " - Run 5 completed.\n",
      "GPU reset warning for /physical_device:GPU:0: Failed parsing device name: '/physical_device:GPU:0'. Note a valid device string should at least contain a device type and a device index, like \"GPU:0\".\n",
      "Parameters: {'n_estimators': 50, 'max_depth': 4, 'min_samples_split': 5, 'base_seed': 42, 'num_runs': 8, 'epochs_per_run': 10, 'run_num': 6}\n",
      " - Training model 6...\n"
     ]
    }
   ],
   "source": [
    "# Model builder with variability (different random seeds)\n",
    "def create_random_forest_with_variability(config):\n",
    "    \"\"\"Create Random Forest with different random seed each run.\"\"\"\n",
    "    global _run_counter\n",
    "    _run_counter += 1\n",
    "    \n",
    "    base_seed = config.get('base_seed', 42)\n",
    "    current_seed = base_seed + _run_counter\n",
    "    \n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=config.get('n_estimators', 100),\n",
    "        max_depth=config.get('max_depth', None),\n",
    "        min_samples_split=config.get('min_samples_split', 2),\n",
    "        min_samples_leaf=config.get('min_samples_leaf', 1),\n",
    "        random_state=current_seed,\n",
    "        bootstrap=True\n",
    "    )\n",
    "    \n",
    "    return ScikitLearnModelWrapper(rf, model_id=f\"random_forest_run_{_run_counter}\")\n",
    "\n",
    "# Test configuration\n",
    "rf_config = ModelConfig({\n",
    "    'n_estimators': 50,\n",
    "    'max_depth': 4,\n",
    "    'min_samples_split': 5,\n",
    "    'base_seed': 42\n",
    "})\n",
    "\n",
    "print(f\"\\n2. Running Random Forest Variability Study...\")\n",
    "_run_counter = 0  # Reset counter\n",
    "\n",
    "rf_results = cr.run_variability_study(\n",
    "    model_builder=create_random_forest_with_variability,\n",
    "    data_handler=data_handler,\n",
    "    model_config=rf_config,\n",
    "    num_runs=8,  # Reasonable number for testing\n",
    "    epochs_per_run=None\n",
    ")\n",
    "\n",
    "print(f\"\\nRandom Forest Results:\")\n",
    "print(rf_results.summarize())\n",
    "\n",
    "# Extract and analyze results\n",
    "rf_accuracies = rf_results.get_final_metrics('val_accuracy')\n",
    "rf_values = list(rf_accuracies.values())\n",
    "\n",
    "print(f\"\\nDetailed Analysis:\")\n",
    "print(f\"Random Forest accuracies: {[f'{v:.3f}' for v in rf_values]}\")\n",
    "print(f\"  Mean: {np.mean(rf_values):.4f} ± {np.std(rf_values):.4f}\")\n",
    "print(f\"  Range: [{np.min(rf_values):.3f}, {np.max(rf_values):.3f}]\")\n",
    "print(f\"  Coefficient of Variation: {np.std(rf_values)/np.mean(rf_values)*100:.1f}%\")\n",
    "\n",
    "# Test the new sklearn-specific plotting functionality\n",
    "print(f\"\\n3. Testing sklearn-Specific Plotting Functions...\")\n",
    "\n",
    "try:\n",
    "    print(\"   Creating sklearn variability summary plot...\")\n",
    "    plot_sklearn_variability_summary(\n",
    "        all_runs_metrics_list=rf_results.all_runs_metrics,\n",
    "        final_metrics_series=rf_results.final_val_accuracies,\n",
    "        metric='accuracy',\n",
    "        show_individual_runs=True,\n",
    "        show_histogram=True, \n",
    "        show_boxplot=True\n",
    "    )\n",
    "    \n",
    "    print(\"   sklearn plotting completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   sklearn plotting failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# Test statistical analysis if available\n",
    "print(f\"\\n4. Testing Statistical Analysis...\")\n",
    "\n",
    "try:\n",
    "    from caracal.analysis import mann_whitney_test, shapiro_wilk_test\n",
    "    \n",
    "    # Test normality of results\n",
    "    rf_series = pd.Series(rf_values, name='Random Forest Accuracy')\n",
    "    \n",
    "    normality_result = shapiro_wilk_test(rf_series)\n",
    "    print(f\"   Normality Test (Shapiro-Wilk):\")\n",
    "    print(f\"     W statistic: {normality_result.statistic:.4f}\")\n",
    "    print(f\"     P-value: {normality_result.p_value:.4f}\")\n",
    "    print(f\"     Normal distribution: {'Yes' if not normality_result.is_significant() else 'No'}\")\n",
    "    \n",
    "    # Test if results are significantly different from 90% accuracy\n",
    "    high_performance = pd.Series([0.9] * len(rf_values), name='90% Benchmark')\n",
    "    \n",
    "    benchmark_test = mann_whitney_test(rf_series, high_performance)\n",
    "    print(f\"\\n   Benchmark Comparison (vs 90% accuracy):\")\n",
    "    print(f\"     Mann-Whitney U: {benchmark_test.statistic:.3f}\")\n",
    "    print(f\"     P-value: {benchmark_test.p_value:.4f}\")\n",
    "    print(f\"     Effect size: {benchmark_test.effect_size:.3f} ({benchmark_test.effect_size_interpretation})\")\n",
    "    print(f\"     Conclusion: {benchmark_test.conclusion}\")\n",
    "    \n",
    "    print(f\"   Statistical analysis completed successfully!\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(f\"   Statistical analysis not available (missing scipy)\")\n",
    "except Exception as e:\n",
    "    print(f\"   Statistical analysis failed: {e}\")\n",
    "\n",
    "# Test enhanced results object methods\n",
    "print(f\"\\n5. Testing Enhanced Results Object...\")\n",
    "\n",
    "try:\n",
    "    available_metrics = rf_results.get_available_metrics()\n",
    "    print(f\"   Available metrics: {available_metrics}\")\n",
    "    \n",
    "    # Test DataFrame conversion\n",
    "    results_df = rf_results.to_dataframe()\n",
    "    print(f\"   Results DataFrame: {results_df.shape}\")\n",
    "    print(f\"   Sample of results:\")\n",
    "    print(results_df[['run_id', 'final_val_accuracy']].head(3).to_string(index=False))\n",
    "    \n",
    "    print(f\"   Enhanced results object working correctly!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   Enhanced results object failed: {e}\")\n",
    "\n",
    "# Cleanup\n",
    "print(f\"\\n6. Cleanup...\")\n",
    "try:\n",
    "    os.unlink(iris_path)\n",
    "    os.rmdir(temp_dir)\n",
    "    print(f\"   Temporary files cleaned up successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"   Cleanup warning: {e}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"SKLEARN TEST COMPLETED!\")\n",
    "print(f\"Random Forest Performance: {np.mean(rf_values):.4f} ± {np.std(rf_values):.4f}\")\n",
    "print(f\"Framework Status: ✓ sklearn models working with appropriate visualization\")\n",
    "print(f\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500dd10c-a058-4df6-ba5e-47cc99aabeeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
